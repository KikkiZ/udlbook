# Chapter 1 Introduction

**人工智能**（Artificial Intelligence，AI）是与构建模拟智能行为相关的系统。它含有多种方法，包括基于逻辑、搜索和概率推理的方法。**机器学习**（Machine Learning，ML）是人工智能的一个子集，它通过将数理模型拟合到观察到的数据来学习做出决策。机器学习领域出现了爆发性的增长，并且它现在几乎与人工智能同义，然而这并不准确。

**深度神经网络**（deep neural network）是机器学习模型的一种，而用模型拟合数据的过程被称为**深度学习**（deep learning）。在撰写此文章时，深度神经网络是最强大、最实用的机器学习模型，并且在日常生活中经常遇到。使用**自然语言处理**算法（Natural Language Processing，NLP）将一种语言翻译到另一种语言、使用**计算机视觉**系统（Computer Vision，CV）在互联网上搜索一些特定的图像、或者通过**语音识别**接口（speech recognition）与语音助手交谈都是常见的使用场景。这些应用程序都由深度学习提供支持。

如标题所示，本书旨在帮助刚接触该领域的读者了解深度学习背后的原理。这本书既没有理论化的证明过程，也几乎没有实用的代码。本书的目标是解释基本思想，读完这本书后，读者将能把深度学习应用在没有现有成功应用的新领域。

机器学习方法大致可以分为**有监督学习**（supervised learning）、**无监督学习**（unsupervised learning）和**强化学习**（reinforcement learning）三个领域。在撰写本文时，三个领域的前沿方法都依赖于深度学习，如图1.1所示。这种分类方法也一定程度上反映在全书的组织结构中。

<img src="https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401221950571.jpg" alt="图1.1" style="zoom: 25%;" />

[图1.1 机器学习是将数理模型与观测到的数据进行拟合的人工智能领域。它可以粗略的分为有监督学习、无监督学习和强化学习三类。深度神经网络对这些领域都有贡献。]

## 1.1 Supervised learning

有监督学习定义了一个从输入数据到输出预测的映射。在接下来的一节中，我们将讨论输入、输出、机器学习模型以及什么是”学习“模型。

### 1.1.1 Regression and classification problems

图1.2描述了几种回归和分类问题。在每个例子中，都有一个具有现实意义的输入（语句、音频或图像等），并将其编码为一个数字向量。机器学习模型将输入映射到输出向量，然后将其”翻译“回有现实意义的预测。目前，我们重点关注输入和输出，并且将模型视为一个黑盒，它接受一个向量并返回另一个向量。

<img src="https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401222025958.jpg" alt="1" style="zoom: 80%;" />

[图1.2 回归和分类问题 a）这个回归模型使用一个数字向量来表示财产，并预测其价格。 b）这个多元回归模型使用有机物的分子结构来预测其融点和沸点。 c）这个二分类模型使用餐厅的评论并将其分类为正面或负面评论。 d）这个多分类问题将音频归类到多个流派之一。 e）这是另一个多分类问题，它将输入的图像分类到多个可能的类别之一里。]

图1.2a中的模型根据输入的房屋面积和卧室数量等特征组成的数字向量预测房价。这是一个**回归问题**（regression），因为模型返回一个确切的数，而非某个类别。相比之下，图1.2b中的模型将分子结构作为输入，并由此预测该分子的融点和沸点。这是一个**多元回归问题**（multivariate regression），因为它预测多个结果。

图1.2c中的模型接收一个包含餐厅评论的文本作为输入，并预测该评论是正面还是负面评论。这是一个**二分类问题**（binary classification），因为模型将输入匹配到预设的两个类别之一。输出向量包含输入属于每个类别的概率。图1.2d和1.2e描述了**多分类问题**（multiclass classification）。此时，模型将输入分配给N个类别（N>2）。第一种情况，输入是一个音频文件，而模型将预测它归属于那个流派。第二种情况下，输入是一副图像，模型预测它包含哪个物品。模型返回一个固定长度的向量，该向量包含归属于每个类别的概率。

### 1.1.2 Inputs

图1.2中的输入数据变化范围广泛。在第一个房价预测的例子中，输入是一个固定长度包含有特殊含义的向量。这是一个由列表数据构成的例子，因为输入数据没有潜在的内部结构。如果我们调整列表数据的顺序，建立一个新的模型，那我们获得的预测结果将保持不变。

与之相对的，餐厅评论例子中的输入是一段文本。这是一个可变长度的输入，它取决于评论中单词的数量，并且在这个例子中，单词的顺序是十分重要的。例如，”my wife ate the chicken“与”the chicken ate my wife“表达的是不同的意思，即使它们由相同的单词组成。文本在传递给模型之前必须编码成数值的形式。而在这个例子里我们使用大小为10,000的固定词汇表，并将单词索引串联成一个向量。

对于音乐分类的例子来说，输入向量可能是一个十秒长固定大小的片段，但是有非常高的维度。数字音频的采样频率通常为44.1kHz，因此每一个十秒的片段由44.1万个采样点组成。显然，有监督学习模型必须能够处理大量输入数据。在图像分类的例子中，每个像素由一组RGB值组成，输入规模也是非常庞大的。并且，它的结构是二维的，转换为输入的一维向量后即使不相邻也密切相关。

最后，考虑预测分子融点和沸点的模型的输入。一个分子可能包含不同数量的原子，这些原子可能会通过不同的方式连接。这种情况下，我们必须将分子的几何结构和分子式同时传递给模型。

### 1.1.3 Machine learning models

到目前为止，我们仍将机器学习模型视为一个黑盒，它接受一个输入向量并返回一个输出向量。但在这个黑盒中到底发生了什么？盒子里有薛定谔的猫吗？考虑一个从年龄预测儿童身高的模型，如图1.3所示。这个机器学习模型描述了平均身高随年龄变化的函数，青色曲线描述了年龄与预测身高的关系。当我们输入一个年龄，模型将返回一个升高。例如，如果输入是10岁，那么模型预测的身高将是139厘米。

![1](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401231459792.jpg)

[图1.3 机器学习模型 该模型代表了输入（儿童年龄）和输出（儿童身高）之间的关系。使用特定关系的数据用来训练模型，这些数据有输入-输出对组成（橙色点）。当我们训练模型时，我们通过搜索可能的关系式来描述数据对。在这里，训练好的模型关系式用青色曲线表示，可以用来计算任何年龄的身高。]

更准确地说，该模型描述了一个将输入映射输出的方程组，这个方程与由输入-输出对组成的**训练数据**（training data）相匹配。在图1.3中，这些输入-输出对用橙色点表示，我们可以看到模型合理的描述了这些数据。当我们讨论**训练**（training）或**拟合**（fitting）一个模型时，实际上是在说通过这一些可能的方程来搜索输入和输出有关的方程，以找到能最准确描述训练数据的方程。

图1.2中的模型需要有标记的输入-输出对进行训练。例如，音乐分类模型需要大量的音频片段，而这些片段需要人们手动进行类型标记。这些输入-输出对在训练过程中扮演者监督者的角色，由此也诞生了**监督学习**（supervised learning）一词。

### 1.1.4 Deep neural networks

本书关注的深度神经网络是一种特别有用的机器学习模型。它们可以表示输入和输出间的关系的一组方程，并且很容易通过这组方程描述训练数据间的关系。

深度神经网络可以处理非常庞大、长度可变、包含多种内部结构的输入。它们可以输出单个实数（回归模型）、多个实数（多元回归模型）、匹配两个或多个类别的概率（二分类模型和多分类模型）。正如下一节将要学到的（图1.4），它们的输出也可能非常庞大、长度可变、并且包含内部结构。我们可能很难想象具有这些性质的方程，我们可以带着这些好奇去继续学习。

### 1.1.5 Structured outputs

图1.4a展示了一个用于语义分割的多元二分类模型。在这个例子里，输入图像的每个像素被分配一个二进制标签，它表明了该像素是属于奶牛还是背景。图1.4b展示了一个多元回归模型，其中输入的是街道场景图像，输出的是每个像素的景深。在这两个例子里，输出都是多维度且结构化的。然而，这种结构与输入密切相关，并且可以对输入加以利用。例如第一个例子中，一个像素被标记为奶牛，那么具有相似RGB值的邻居可能具有相同的标签。

图1.4c-e展示了三个模型，它们的输出都有复杂的结构，且与输入的联系没有那么紧密。图1.4c展示了一个将音频转译为文本的模型。图1.4d展示了一个将英文文本翻译为法语文本的模型。图1.4e展示了一个非常具有挑战性的任务，模型的输入是一段描述性文本，而模型将生成与该描述相匹配的图像。

<img src="https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401231600971.jpg" alt="1" style="zoom:80%;" />

[图1.4 具有结构化输出的有监督学习任务 a）语义分割模型将RGB图像映射为二进制图像，表明每个像素属于背景还是奶牛[^1]。 b）单眼深度估计模型将RGB图像映射为输出图像，其中每个像素代表深度[^2]。 c）音频转录模型将音频样本映射为一段文本。 d）翻译模型将英文文本映射到法语翻译。 e）图像合成模型将一段描述文本映射为一张图像，例子来自于https://openai.com/dall-e-2/。在每个例子中，输出都具有复杂的内部结构或语法。在某些情况下，许多输出与输入相匹配。]

原则上来说，后三个任务可以在标准的有监督学习框架中解决，但由于下列原因使模型训练的难度更大。首先，输出可能没有唯一准确的值；英语句子到法语句子的多种有效翻译以及与任何描述匹配的多个图像。其次，输出具有确切的结构；并非所有的单词组合都能构成有效的英语和法语句子，也并非所有RGB像集合素能组成合理的图像。除了学习输入到输出的映射之外，我们还必须尊重输出的“语法”。

幸运的使，这种“语法”可以在不需要输出标签的情况下进行学习。例如，我们可以通过学习大量文本数据来学习如何生成合理的有效的英语语句。在下一节，我们将了解到无需标签的**无监督学习模型**（unsupervised learning models）。

## 1.2 Unsupervised learning

从没有相应输出结果的输入数据中构建模型称为**无监督学习**（unsupervised learning）。输出标签的的缺失意味着模型无法“监督”。这类模型目标不是学习从输入到输出的映射，而是描述或理解数据的结构。有监督学习相比，输入数据可能有非常不同的特征，它可以是离散或连续的、低维或高维的、以及定长或边长的。

### 1.2.1 Generative models

本书重点介绍**生成式无监督模型**（generative unsupervised models），该模型学习合成在统计上与训练数据无法区分的新数据示例。一些生成式模型显式地描述了输入域上的概率分布，这里通过从该分布中采样生成新的分布。其他的模型只是学习一种产生新例子的机制。

最先进的生成式模型可以合成非常逼真而与训练样本不同的例子。它们在生成图像（图1.5）和文本（图1.6）方面尤为成功。它们还可以在某些输出被预先确定的约束下合成数据，也被称为**条件合成**（conditional synthesis）。例如图像修复（图1.7）和文本补全（图1.8）就是其中的例子。事实上，现代文本生成模型非常强大，以至于它们可以给人一种智能的感觉。给定一段文本后面跟着一个问题，模型通常可以根据生成最可能的文字来“填补”缺失的答案。然而，实际上，该模型只了解语言的统计信息，并不理解其答案的意义。

![1](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401232154577.jpg)

[图1.5 图像生成模型 左边两幅图像是由以猫的图片为训练数据的模型生成，它们并非真实的猫，而是来自概率模型的样本。右边两幅图像是由以建筑图片为训练数据的模型生成的。[^3]]

![image-20240123215335304](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401232153349.png)

[图1.6 一个由本文数据生成模型合成的短篇故事。该模型描述了一个将概率分配给每个输出字符串的概率分布。从模型中采样可以生成遵循训练数据统计规律（这里是短篇故事）但从未见过的字符串。]

![1](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401232155697.jpg)

[图1.7 图像修补 在原始图像（左图）里，男孩被金属电缆遮挡。这些不受欢迎的区域被移除（中间），生成模型需要在保持剩余像素不变的约束条件下合成一张新的图像（右图）。[^4]]

![image-20240123215303999](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401232153073.png)

[图1.8 条件文本生成 给定一段初始文本（黑色字符），文本生成模型可以通过合成“缺失”的部分，从而使字符串的延续具有合理性。[^5]]

![1](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401232155311.jpg)

[图1.9 人脸的变化 人脸大约有42块肌肉，因此可以用仅由42个数字来描述在相同光照条件下同一个人的不同图像。通常情况下，图像、音乐和文本的数据集可以用相对较少的基础变量来描述，尽管将这些变量与特定的物理机制联系起来通常是比较困难的。[^6]]

### 1.2.2 Latent variable

一些生成模型利用了数据的维度可以比观测到的原始变量数量要低这一结论。例如，有实际意义的英语句子的数量要远远少于将单词随机排列组合所形成的字符串的数量。同样，现实世界中的图像只是可以通过为每个像素随机选择RGB值而创建的图像集合的子集。这是因为图像是由物理过程产生的，如图1.9所示。

![1](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401241624992.jpg)

[图1.10 潜变量 许多生成模型使用深度学习模型来描述一个低维“潜在”变量与观测到的高维数据之间的关系。而这些潜在变量具有简单的概率分布，因此，可以通过在潜变量的简单分布上进行采样，然后使用深度学习模型将样本映射到观测数据空间来生成新的示例。]

![1](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401241640949.jpg)

[图1.11 图像插值 在每一行中，两侧的图像都是真实的，中间的三幅图像表示由生成模型创建的一系列插值。支撑这些插值的生成模型已经学习到，所有图像都可以由一组基础的潜变量创建。通过找到这些变量对于两个真实图像的值，进行插值，然后使用这些中间变量来创建新的图像。我们可以生成既在视觉上具有可信度，又混合了两个原始图像特征的中间结果。图像分别来自[^7][^8]]

这也就引出了一个想法：我们可以用较少数量的**潜变量**（latent variables）来描述每个数据示例。在这里，深度学习的作用是描述这些潜变量与数据之间的映射关系。这些潜变量与通常设计具有简单的概率分布。通过从这个分布中采样，并将结果通过深度学习模型传递，我们可以创建新的样本，如图1.10所示。

这些模型为处理真实数据提供了新的方法。例如，考虑找出支撑两个真实示例的潜变量，我们可以通过在这些例子的潜在表示之间进行插值，并将中间位置映射回数据空间来实现在这些实例间插值，如图1.11所示。

### 1.2.3 Connecting supervised and unsupervised learning

具有潜变量的生成模型也可以用与具有结构化输出的有监督学习模型，如前图1.4所示。例如，考虑学习预测标题对应的图像。与直接将文本输入映射到图像不同，我们可以通过学习解释文本的潜变量与解释图像的潜变量之间的关系来达成目标。

这么做有三个有点。首先，由于输入和输出维度较低，我们需要更少的数据来学习这个映射；其次，我们更有可能生成一个看起来合理的图像，任何有意义的潜变量都应该产生看起来像一个合理的数据示例；第三，如果我们在两组潜变量间的映射或从潜变量到图像的映射中引入随机性，那么我们可以生成多幅图像，这些图像都能很好地被描述，如图1.12所示。

![1](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401241925261.jpg)

[图1.12 从标题“时代广场上玩滑板的泰迪熊”中生成的多个图像。[^8]]

## 1.3 Reinforcement learning

机器学习的最后一个领域是强化学习。该领域引入了代理的概念，该代理存活在一个世界中，并且可以在每个时间点执行某些操作。这些操作会改变系统的状态，但不是以确定的方式改变。采取行动可以产生奖励，强化学习的目标是让代理学会选择能带来高回报的行动。

一个复杂的情况是，奖励可能会在采取行动后的一段时间内发生，因此将奖励与行动关联起来并不简单。这被称为**时间信用分配问题**（temporal credit assignment problem）。当代理在学习时，它必须权衡对已有知识的**探索**（exploration）和**利用**（exploitation）。也许代理已经学会了如何获得一定的奖励，它应该继续遵循它已知的策略，还是去尝试其他的机会来看它是否可以改进？

### 1.3.1 Two examples

考虑教人形机器人运动这个问题，机器人可以在给定的时间执行一定数量的动作，并且这些动作会改变当前状态（姿势）。我们可以奖励机器人到达障碍跑道上的检查点，而为了到达这些检查点，它必须执行许多操作。在这个过程中，机器人不清楚哪些操作在收到奖励时做出了贡献，而哪些操作无关紧要。这就是时间信用分配问题的一个实例。

第二个例子是学习下棋，代理在给定的时间内可以执行一组符合国际象棋走法的动作。然而，这些操作以非确定性的方式改变系统的状态。对于代理执行的任何动作，对方可能以不同的走棋方式做出反应。在这里，我们可以建立一个根据捕获棋子来设置奖励的结构，也可以在比赛胜利时获得一个奖励。后一种情况是时间信用分配的一个极端情形，系统必须学习它所做的许多动作中哪一个会造成成功或失败。

在这两个例子中，探索和利用的权衡也很重要。机器人可能已经发现，它可以通过侧躺并用一条腿来推动以向前移动。这种策略将会让机器人前进并获得奖励，但比起用双腿保持平衡行走的最佳解决方案慢得多。因此，它面临着一个两难的抉择：使用已知的知识笨拙的沿地板挪动，或是探索更前进得更快的方案。类似的，在国际象棋的例子中，代理可能会学到一组合理下棋方法。它同样面临应该利用这些已知的知识还是探索不同的下棋方案这样一个两难的问题。

深度学习如何融入强化学习框架也许并不明显。有几种不同的方法，一种方法是使用深度神经网络来构建从观测状态到动作的映射，这被称为**策略网络**（policy network）。在机器人行走的例子中，策略网络将学习从传感器测量到关节运动的映射。而在下象棋的例子中，网络将学习一个从棋盘当前状态到移动选择的映射，如图1.13所示。

![1](https://raw.githubusercontent.com/KikkiZ/ChartBed/main/typora/202401242045231.jpg)

[图1.13 用于强化学习的策略网络 将深度神经网络融入强化学习的一种方法是让它们定义从状态到动作的映射，这种映射被称为策略。[^9]]

## 1.4 Structure of book

本书的结构使用了与这篇导论相似的结构。第2-9章我们将深入了解有监督学习。我们描述了浅层神经网络和深层神经网络，然后讨论如何去训练它们并测定和提升它们的表现情况。第10-13章讲述了深度神经网络常见的结构变化，包括卷积神经网络、残差链接和Transformer。这些架构被广泛的使用在有监督、无监督和强化学习中。

第14-18章是利用深度神经网络进行无监督学习。我们将在每章中讲一个现代深度生成模型，分别是：生成式对抗网络、变分自编器、归一化流和扩散模型。第19章是对深度强化学习的简介。这是一个容易引起争论问题，因此本章的内容是浅显的，但对于不熟悉该领域的读者来说是一个好的起点。

尽管本书的标题是《理解深度学习（Understanding Deep Learning）》，但人们对深度学习的某些方面仍然知之甚少。第20章提出了一些基本问题，为什么深度网络如此容易训练？为什么它们具有泛化能力？为什么它们需要这么多参数？它们需要很深的网络结构吗？一路上，我们将会探索一些意想不到的现象，例如损失函数的结构、双峰下降等。

## 1.5 Ethics

如果不讨论人工智能的伦理影响就写这本书是不负责任的。这项强大的技术将至少与电力、内燃机、晶体管或互联网一样改变世界。在医疗保健、设计、娱乐、交通、教育和几乎每个商业领域，人工智能的潜在好处是巨大的。然而，科学家和工程师往往对他们工作的结果过于乐观，而它们的潜在危害同样巨大。下面重点阐述了五个问题。

**偏见和公平**：如果我们训练一个根据历史数据预测个人的薪资水平的系统，那么这个系统将重现历史偏差；例如，它可能会预测女性的工资应该低于男性。已经有一些这样的案例成为了国际新闻报道：超分辨率人脸图像的人工智能系统使非白人看起来更白；当一个图像生成系统被要求合成律师的照片时，它只生成男性的照片。人工智能算法决策可能会隐性的巩固或加剧现有的偏见，进一步讨论请看[^10]。

**可解释性**：深度学习系统会做出很多决策，但我们通常不能确切知道它们如何做出决策或基于哪些信息做出的决策。它们可能包含数十亿个参数，我们无法通过检查来了解它们是如何工作的。这催生了可解释人工智能的子领域。一个比较成功的领域是进行局部解释。我们无法解释整个系统，但我们可以对为什么做出特定决定做出可解释的描述。然而，是否有可能构建对其用户或其创建者完全透明的复杂决策系统仍然未知。进一步讨论请看[^11]。

**人工智能武器化**：所有重要技术都直接或间接应用于战争，可悲的是，暴力冲突似乎是人类行为的不可避免的特征。人工智能可以说是有史以来最强大的技术，毫无疑问将在军事领域得到广泛部署。事实上，这种情况已经发生，可以在[^12]中查看更多。

**权力集中**：世界上最强大的公司之所以大量投资于人工智能，并不是出于改善人类命运的善意。他们知道这些技术将使他们获得巨额利润。和任何先进技术一样，人工智能很可能会将权力集中在少数控制它的组织手中。自动化目前由人类完成的工作将改变经济环境，并不成比例地影响那些薪酬较低、技能较少的劳动者的生计。乐观主义者认为，在工业革命期间也发生了类似的颠覆，导致工作时间缩短。事实上，我们并不清楚大规模采用人工智能对社会会产生什么影响，进一步讨论请看[^13]。

**生存风险**：人类面临的主要风险都源于技术。气候变化是工业化推动的结果；核武器源于物理研究；流行病更有可能扩散，传播得更快，因为交通、农业和建筑方面的创新使人口更多、更密集、更互联。人工智能带来新的生存风险。我们应该非常谨慎地构建比人类更具能力和扩展性的系统。在最乐观的情况下，它将使所有者拥有巨大的权力。在最悲观的情况下，我们将无法控制它，甚至无法理解它的动机，进一步讨论请看[^14]。

这个列表远非详尽无遗。人工智能也可能导致监视、虚假信息、侵犯隐私、欺诈和操纵金融市场，而训练人工智能系统所需的能源也会导致气候变化。此外，这些担忧并非臆测，已经有许多人工智能在伦理上可疑的应用案例[^15]。此外，互联网的最近的历史表明，新技术可能以意想不到的方式造成伤害。上世纪八十年代和九十年代的在线社区几乎无法预测假新闻、垃圾邮件、网络骚扰、欺诈、网络欺凌、恋爱骚扰文化、政治操纵、揭露个人信息、网络极端化和报复色情的泛滥现象。

每个研究人工智能的人，包括研究者、科学家或撰写相关书籍的人，都应该思考科学家对其技术使用的责任程度。我们应该考虑到资本主义主导了人工智能的发展，而法律进步和为社会福祉而部署的进展可能严重滞后。我们应该反思作为科学家和工程师是否能够控制这一领域的进展，并减少潜在的危害。我们应该考虑我们愿意为何种组织工作。他们在减少人工智能潜在危害方面有多认真？他们只是为了减少声誉风险而进行“道德洗白”，还是真正实施机制来阻止道德可疑的项目？

我们鼓励所有读者进一步研究这些问题。网址为https://ethics-of-ai.mooc.fi/的在线课程是一个很好的起点。附录D中提供了关于人工智能伦理的更多阅读材料。如果你是一位正在使用这本书进行教学的教授，鼓励你与学生们讨论这些问题；如果你是一名学生，所上的课程没有涉及这些问题，那么请向教授施压，让他们引入相关内容；如果你在企业环境中部署或研究人工智能，鼓励你审视雇主的价值观，并在有需要时帮助改变它们或选择离开。

## 1.6 Other books

本书自成体系，但仅限于深度学习领域。它旨在成为《Deep Learning[^16]》的精神继承者，这是一本神奇的书，但并不涵盖近年的研究进展。为了更广泛的研究机器学习，最新的百科全书式的材料是《Probabilistic Machine Learning[^17]》。然而，《Pattern Recognition and Machine Learning[^18]》仍是一本优秀且有关联的书籍。

如果你喜欢本书，那么我以前的著作《Computer Vision：Models，Learning，and Inference[^19]》仍然值得一读。它的一些部分已经过时，但它包含了对概率的全面介绍，还有对贝叶斯方法、潜变量模型、计算机视觉几何、高斯过程和图形模式的良好介绍。它使用了与本书相同的标记法，并且可以在网络上找到书籍资源。关于图模型和高斯过程的更多细节可以在《Probabilistic Graphical Models：Principles and Techniques[^20]》和《Gaussian Processes for Machine Learning[^21]》中找到。

对于数学的背景知识请参考《Mathematics for Machine Learning[^22]》。更多面向编写代码的方法请参考《Dive into Deep Learning[^23]》。关于计算机视觉的参考标准有即将出版的《Computer Vision：A Deep Learning Approach[^24]》一书。学习图神经网络的一个很好的起点是《Graph Representation Learning[^25]》。关于强化学习的权威著作是《Reinforcement Learning：An Introduction[^26]》。

## 1.7 How to read this book

本书的其他章节都有一个正文部分、一个注释部分和一些练习题。正文部分是独立的，无需参考本章的其他部分，并且本书所用到的数理知识已经尽可能的融入到正文中了。然而，对于一些会干扰主线内容的论点将会被添加到背景材料中，并提供一些参考知识。本书使用的大多数记法都是标准的，但有些惯例使用的范围较小，我们鼓励读者去附录A中查阅。

正文部分包含了许多新颖的深度学习模型和结果的插图与可视化图像。我一直努力为现有的概念提供新的解释，而不仅仅是对他人的工作进行总结。深度学习是一个全新的领域，有时对现有现象的理解并不清晰。我试图弄清楚这些现象在什么情况下发生，以及对其谨慎严谨的解释。

仅在描述结论的章节正文中才包含参考文献。在其他章节中，这些可以在本章末尾的注释部分找到。我一般不尊重正文中的历史先例；如果当前技术的祖先不再有用，那么我将不会提及。但是，该领域的历史发展在会在注释部分进行讨论，并希望尽可能公平讨论。这些注释被组织成段落，并提供进一步学习的指导。它们应该帮助读者在子领域中的定位并理解它与机器学习其他部分的关系。注释部分不如正文那么独立，您可以根据您对背景知识的理解程度与感兴趣程度进行选读。您可能会发现这些部分或多或少有用。

每一章都有一些相关的问题，它们在正文部分标注了出来。正如 George Pólya 所说：“Mathematics, you see, is not a spectator sport.（你看，数学并不是一项观赏性的运动）”毫无疑问他是对的，我强烈建议你边学边尝试这些问题。在某些情况下，它们提供的见解将帮助您理解正文部分。这些问题在相关网站上提供的答案并用星号表示。

最后，人工智能的进步速度使得这本书难免是一部不断调整的著作。如果你发现难以理解的部分、明显的遗漏或是无关紧要的部分，请通过相关网站联系我。让我们一起使下一版更加完善。

## Reference

[^1]: Noh, H., Hong, S., & Han, B. (2015). Learning deconvolution network for semantic segmentation. IEEE International Conference on Computer Vision, 1520–1528.
[^2]: Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Roth, S., & Schiele, B. (2016). The Cityscapes dataset for semantic urban scene understanding. IEEE/CVF Computer Vision & Pattern Recognition, 1877–1901.
[^3]: Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., & Aila, T. (2020b). Analyzing and improving the image quality of StyleGAN. IEEE/CVF Computer Vision & Pattern Recognition, 8110–8119.
[^4]: Saharia, C., Chan, W., Chang, H., Lee, C., Ho, J., Salimans, T., Fleet, D., & Norouzi, M. (2022a). Palette: Image-to-image diffusion models. ACM SIGGRAPH.
[^5]: Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Neural Information Processing Systems, 33, 18771901.
[^6]: Holland, C. A., Ebner, N. C., Lin, T., & SamanezLarkin, G. R. (2019). Emotion identification across adulthood using the dynamic faces database of emotional expressions in younger, middle aged, and older adults. Cognition and Emotion, 33(2), 245–257.
[^7]: Sauer, A., Schwarz, K., & Geiger, A. (2022). StyleGAN-XL: Scaling StyleGAN to large diverse datasets. ACM SIGGRAPH.
[^8]: Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., & Chen, M. (2022). Hierarchical textconditional image generation with CLIP latents. arXiv:2204.06125.
[^9]: Pablok, J. (2017). Chess pieces and board improved. Wikimedia Commons. Retrieved Jan- uary 17, 2023. https://commons.wikimedia. org / wiki / File: Chess_ pieces_and_board_improved.svg.
[^10]: Binns, R. (2018). Algorithmic accountability and public reason. Philosophy & Technology, 31(4), 543–556.
[^11]: Grennan, L., Kremer, A., Singla, A., & Zipparo, P. (2022). Why businesses need explainable AI—and how to deliver it. McKinsey, Septem-ber 29, 2022. https://www.mckinsey.com/ capabilities/quantumblack/our-insights/ why-businesses-need-explainable-ai-and-how-to-deliver-it/.
[^12]: Heikkilä, M. (2022). Why business is booming for military AI startups. MIT Technology Review, July 7 2022. https://www.technologyreview. com/2022/07/07/1055526/why-business-is-booming-for-military-ai-startups/.
[^13]: David, H. (2015). Why are there still so many jobs? The history and future of workplace automation. Journal of Economic Perspectives, 29(3), 3–30.
[^14]: Tegmark, M. (2018). Life 3.0: Being human in the age of artificial intelligence. Vintage.
[^15]: Dao, D. (2021). Awful AI. Github. Retrieved January 17, 2023. https : //github.com/daviddao/awful-ai.
[^16]: Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT Press.
[^17]: Murphy, K. P. (2022). Probabilistic machine learning: An introduction. MIT Press.
[^18]: Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.
[^19]: Prince, S. J. D. (2012). Computer vision: Models, learning, and inference. Cambridge University Press.
[^20]: Koller, D., & Friedman, N. (2009). Probabilistic graphical models: Principles and techniques. MIT Press.
[^21]: Williams, C. K., & Rasmussen, C. E. (2006). Gaussian processes for machine learning. MIT Press.
[^22]: Deisenroth, M. P., Faisal, A. A., & Ong, C. S. (2020). Mathematics for machine learning. Cambridge University Press.
[^23]: Zhang, A., Lipton, Z. C., Li, M., & Smola, A. J. (2023). Dive into deep learning. Cambridge University Press.
[^24]: Torralba, A., Freeman, W., & Isola, P. (forthcoming). Computer vision: A deep learning approach. MIT Press.
[^25]: Hamilton, W. L. (2020). Graph representation learning. Synthesis Lectures on Artifical Intelligence and Machine Learning, 14(3), 1–159.
[^26]: Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An introduction, 2nd Edition. MIT Press.

